## **1. Pré-requisitos**

A etapa de pré-requisitos é o alicerce para garantir que seu ambiente esteja pronto para a instalação e operação do chatbot com o modelo de inteligência artificial LLaMA. Nesta seção, você encontrará todas as informações necessárias sobre hardware, software e configurações iniciais para que o projeto funcione de maneira adequada. Além disso, também é encontrado os passos para configurar a conta no WhatsApp Business, acessar o modelo LLaMA e validar o ambiente antes de avançar.
Esta etapa é importante para evitar problemas futuros e garantir que todos os componentes estejam devidamente instalados e configurados. Revise os requisitos com cuidado e testar cada parte antes de seguir para as próximas etapas.



Detalhando cada requisito:

### **1.1 Hardware**

Dependendo da versão LLaMA ou do nível de processamento desejado, considere as opções abaixo:

- **Configuração Mínima Recomendada**:
  - **RAM**: 
    - 16GB para modelos menores do LLaMA (7B).
    - 32GB ou mais para modelos maiores (13B ou 65B).
  - **GPU**: Uma GPU NVIDIA com suporte a CUDA é altamente recomendada para acelerar inferências e treinos.
    - Memória de GPU: Pelo menos 8GB para inferência com modelos pequenos.
    - Para modelos maiores, GPUs de 16GB ou mais, como NVIDIA A100, RTX 3090 ou 4090.
  - **Armazenamento**:
    - SSD com pelo menos 100GB de espaço livre para armazenar modelos, dados de treinamento e logs.
  - **Processador**:
    - Pelo menos 4 núcleos (8 threads).
    - Processadores como Intel i7/i9 ou AMD Ryzen 7/9 são ideais.

- **Servidor ou Computador Local?**
  - Se o objetivo for usar o chatbot apenas localmente ou em pequena escala, um computador desktop pode ser suficiente.
  - Para uso em produção considere um servidor local dedicado.
.

### **1.2 Software**
#### **Verifique a versão do Node.js**
Antes de instalar o Baileys, confirme a versão do Node.js instalada:
```bash
node -v
```
Certifique-se de que a versão instalada seja compatível com a biblioteca Baileys (recomendada: v16 ou superior).


Certifique-se de que o ambiente operacional tenha as ferramentas necessárias abaixo para instalar e executar o chatbot e a inteligência artificial:

#### **Sistema Operacional**
- **Linux** é preferido devido à facilidade de uso com ferramentas de desenvolvimento e suporte a CUDA.
- Para Windows:
  - Instale o **Windows Subsystem for Linux (WSL2)** para melhor compatibilidade com ferramentas de IA.

#### **Linguagens e Gerenciadores**
- **Python** (3.8 ou superior):
  - Necessário para executar scripts de IA e ferramentas de integração.
  - Instale com:
    ```bash
    sudo apt install python3 python3-pip -y
    ```
- **Node.js** (para integração com WhatsApp):
  - Certifique-se de que você tem o **Node.js** instalado para usar ferramentas como Baileys.
  - Instale com:
    ```bash
    curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -
    sudo apt install nodejs -y
    ```

#### **Docker (Opcional, mas Recomendado)**
Usar Docker facilita a instalação de dependências e mantém o ambiente isolado. Para instalar:
```bash
sudo apt update
sudo apt install docker.io -y
sudo systemctl enable --now docker
```

Para verificar a instalação:
```bash
docker --version
```
.

### **Testes de Pré-Configuração**

Antes de iniciar a instalação e a execução do chatbot, é fundamental validar se o ambiente operacional está configurado corretamente e se todas as ferramentas necessárias estão instaladas. Realizar esses testes garantirá que seu sistema esteja preparado para rodar o chatbot com a inteligência artificial LLaMA de maneira eficaz.

Aqui estão os testes essenciais para garantir que os pré-requisitos estão funcionando corretamente:

---

#### **Verifique a versão do Python**

O Python 3.8 ou superior é necessário para executar os scripts de IA e outras ferramentas do chatbot. Verifique a versão instalada no seu sistema com o seguinte comando:

```bash
python3 --version
```

- Se a versão for inferior à 3.8, você precisará atualizar o Python para garantir compatibilidade com o modelo LLaMA e outras bibliotecas necessárias.
- Caso o Python não esteja instalado, instale-o com:
  ```bash
  sudo apt install python3 python3-pip -y
  ```

---

#### **Teste o Node.js**

O Node.js é necessário para integrar o WhatsApp com a biblioteca Baileys (se você estiver utilizando a API não oficial). Para verificar se o Node.js está instalado corretamente, use:

```bash
node -v
```

- Se a versão não for compatível (recomendada v16 ou superior), instale ou atualize o Node.js:
  ```bash
  curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -
  sudo apt install nodejs -y
  ```

---

#### **Confirme o funcionamento do Docker**

O Docker é opcional, mas altamente recomendado para isolar o ambiente e facilitar a instalação das dependências. Para verificar se o Docker está instalado corretamente e funcionando, execute:

```bash
docker run hello-world
```

- Se a instalação for bem-sucedida, você verá uma mensagem confirmando que o Docker está instalado e funcionando.
- Se o Docker não estiver instalado, use o comando abaixo para instalá-lo:
  ```bash
  sudo apt update
  sudo apt install docker.io -y
  sudo systemctl enable --now docker
  ```

---

#### **Certifique-se de que a GPU está configurada corretamente (se aplicável)**

Se você estiver utilizando uma GPU para acelerar o treinamento e a execução do modelo LLaMA, é essencial verificar se a GPU está configurada corretamente. Para fazer isso, utilize o comando:

```bash
nvidia-smi
```

- Este comando exibe informações sobre a GPU instalada, como a versão do driver e a utilização da GPU.
- Se o comando não for reconhecido, você pode não ter os drivers NVIDIA ou o CUDA instalados. Instale-os com os seguintes comandos:
  ```bash
  sudo apt install nvidia-driver-460
  sudo reboot
  ```

- Após reiniciar, execute novamente o `nvidia-smi` para verificar se a GPU está disponível para uso.

---

#### **Passos Adicionais**

Se algum desses testes falhar, siga as instruções de instalação ou atualização dos componentes correspondentes. A execução bem-sucedida desses testes garante que o ambiente está pronto para rodar o chatbot e o modelo LLaMA, sem problemas técnicos durante a instalação e execução.

  

### **1.3 Outros Requisitos de Ferramentas**

#### **Conta no WhatsApp Business**
Você precisará de acesso à API do WhatsApp para conectar o chatbot.

- **API Oficial**:
  - Registre-se no [Meta for Developers](https://developers.facebook.com/) e crie um aplicativo.
  - Gere um token de acesso e configure o webhook para comunicação com o seu servidor.
  - Necessário um número comercial verificado para usar a API oficial.

- **API Não-Oficial (Baileys)**:
  - O Baileys permite criar um bot para WhatsApp sem precisar da API oficial.
  - Tenha um número de telefone dedicado ao bot para evitar bloqueios.

#### **Modelo LLaMA**
- Acesse o repositório oficial da Meta para LLaMA e solicite o modelo pré-treinado. 
- Certifique-se de cumprir os requisitos de licença.
- Após obter o modelo, extraia os arquivos para um diretório em seu servidor.

#### **Acesso ao Servidor**
- Configure acesso via **SSH** ao servidor local ou nuvem para gerenciar a instalação remotamente.
.

